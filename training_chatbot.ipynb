{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx onnxruntime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-Sma0NAq5wG",
        "outputId": "0ddd5ae4-94b5-4836-aa87-e33b8315eb62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (4.25.5)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.13.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx, humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.17.0 onnxruntime-1.20.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Datos de ejemplo extendidos\n",
        "data = [\n",
        "    (\"hola\", \"¡Hola! ¿Como estas?\"),\n",
        "    (\"¿como estas?\", \"Estoy bien, gracias por preguntar.\"),\n",
        "    (\"adios\", \"¡Adios! Cuidate.\"),\n",
        "    (\"¿cual es tu nombre?\", \"Soy un chatbot simple.\"),\n",
        "    (\"¿que haces?\", \"Estoy aqui para ayudarte.\"),\n",
        "    (\"¿que es python?\", \"Python es un lenguaje de programacion popular.\"),\n",
        "    (\"cuentame un chiste\", \"¿Por que el libro de matematicas estaba triste? Porque tenia muchos problemas.\"),\n",
        "    (\"¿que dia es hoy?\", \"No tengo un calendario, pero puedo ayudarte con otras cosas.\"),\n",
        "    (\"gracias\", \"De nada, estoy para servirte.\"),\n",
        "    (\"¿puedes ayudarme?\", \"¡Claro! Dime en que necesitas ayuda.\"),\n",
        "]\n",
        "\n",
        "# Preprocesamiento del texto\n",
        "def tokenize(sentence):\n",
        "    return sentence.lower().split()\n",
        "\n",
        "def build_vocab(data):\n",
        "    words = set()\n",
        "    for question, _ in data:\n",
        "        words.update(tokenize(question))\n",
        "    return {word: idx for idx, word in enumerate(words)}\n",
        "\n",
        "vocab = build_vocab(data)\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# Convertir texto a tensores\n",
        "def text_to_tensor(text, vocab):\n",
        "    tokens = tokenize(text)\n",
        "    indices = [vocab.get(word, 0) for word in tokens]\n",
        "    return torch.tensor(indices, dtype=torch.float32)\n",
        "\n",
        "# Red neuronal\n",
        "class ChatbotModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size, num_classes):\n",
        "        super(ChatbotModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.fc1 = nn.Linear(embed_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x.long())\n",
        "        x = x.mean(dim=1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        out = self.fc2(x)\n",
        "        return out\n",
        "\n",
        "# Parámetros del modelo\n",
        "embed_size = 8\n",
        "hidden_size = 16\n",
        "num_classes = len(data)\n",
        "model = ChatbotModel(vocab_size, embed_size, hidden_size, num_classes)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "epochs = 500\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    for idx, (question, _) in enumerate(data):\n",
        "        x = text_to_tensor(question, vocab).unsqueeze(0)\n",
        "        y = torch.tensor([idx])\n",
        "        optimizer.zero_grad()\n",
        "        output = model(x)\n",
        "        loss = loss_fn(output, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    if (epoch + 1) % 50 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(data):.4f}\")\n",
        "\n",
        "# Exportar modelo a ONNX\n",
        "example_input = text_to_tensor(\"hola\", vocab).unsqueeze(0)\n",
        "model = model.float()\n",
        "torch.onnx.export(\n",
        "    model,\n",
        "    example_input,\n",
        "    \"chatbot_model.onnx\",\n",
        "    input_names=['input'],\n",
        "    output_names=['output'],\n",
        "    dynamic_axes={'input': {0: 'batch_size', 1: 'sequence_length'}, 'output': {0: 'batch_size'}},\n",
        "    opset_version=11\n",
        ")\n",
        "\n",
        "print(\"Modelo exportado como chatbot_model.onnx\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "585sf3YJVsY9",
        "outputId": "d7edc423-729c-451a-e53f-e5d4846d2b5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [50/500], Loss: 0.0035\n",
            "Epoch [100/500], Loss: 0.0007\n",
            "Epoch [150/500], Loss: 0.0003\n",
            "Epoch [200/500], Loss: 0.0002\n",
            "Epoch [250/500], Loss: 0.0001\n",
            "Epoch [300/500], Loss: 0.0001\n",
            "Epoch [350/500], Loss: 0.0000\n",
            "Epoch [400/500], Loss: 0.0000\n",
            "Epoch [450/500], Loss: 0.0000\n",
            "Epoch [500/500], Loss: 0.0000\n",
            "Modelo exportado como chatbot_model.onnx\n"
          ]
        }
      ]
    }
  ]
}